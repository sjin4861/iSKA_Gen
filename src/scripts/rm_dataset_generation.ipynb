{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6912870",
   "metadata": {},
   "source": [
    "# RM 훈련 데이터셋 생성\n",
    "\n",
    "이 노트북은 Reward Model 훈련을 위한 세 가지 유형의 선호도 쌍 데이터셋을 생성합니다:\n",
    "\n",
    "1. **SPF (Supervised Preference Dataset by Filtering)**: GPT-4o 루브릭 평가 기반\n",
    "2. **IMP (Inter-Model Performance Preference Dataset)**: 모델 성능 차이 기반\n",
    "3. **ICP (Intra-Model Contrastive Preference Dataset)**: 대조적 지문 생성 기반\n",
    "\n",
    "각 데이터셋은 6개 루브릭(평가 지침 완전성, 핵심 주제 명확성, 참고 자료 기반성, 논리적 흐름 및 구조, 한국어 품질, L2 학습자 적합성)에 대해 생성됩니다.\n",
    "- completeness_for_guidelines\n",
    "- core_theme_clarity\n",
    "- reference_groundedness\n",
    "- logical_flow_and_structure\n",
    "- korean_quality\n",
    "- l2_learner_suitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36c2e52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 경로 설정 완료\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# 프로젝트 경로 설정\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "sys.path.append(str(Path.cwd().parent / 'modules'))\n",
    "sys.path.append(str(Path.cwd().parent / 'utils'))\n",
    "\n",
    "print(\"✅ 경로 설정 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c498393",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "from utils.rm_dataset_generator import (\n",
    "    RMDatasetGenerator,\n",
    "    create_spf_dataset,\n",
    "    create_imp_dataset,\n",
    "    create_icp_dataset\n",
    ")\n",
    "\n",
    "print(\"✅ RM 데이터셋 생성기 모듈 로드 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a01b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 설정\n",
    "OPENAI_MODEL = 'gpt-4o'\n",
    "TARGET_PAIRS_PER_RUBRIC = 50  # 테스트용으로 적게 설정\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "print(f'🎯 설정 완료:')\n",
    "print(f'   OpenAI 모델: {OPENAI_MODEL}')\n",
    "print(f'   루브릭당 목표 쌍 수: {TARGET_PAIRS_PER_RUBRIC}')\n",
    "print(f'   랜덤 시드: {RANDOM_SEED}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c45c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 샘플 기본 지문 데이터 생성 (실제로는 기존 생성된 지문을 사용)\n",
    "sample_base_passages = [\n",
    "    {\n",
    "        'id': f'passage_{i:03d}',\n",
    "        'text': f'이것은 샘플 지문 {i}입니다. 한국어로 작성된 교육용 텍스트로, 다양한 주제를 다루고 있습니다. 문법적으로 정확하고 논리적으로 구성되어 있으며, 교육 목적에 적합한 내용을 담고 있습니다. 이 지문은 학습자들이 한국어 읽기 능력을 향상시킬 수 있도록 도와줍니다.',\n",
    "        'topic': f'주제_{i%10}',\n",
    "        'source': 'sample_generation',\n",
    "        'created_at': datetime.now().isoformat()\n",
    "    }\n",
    "    for i in range(1, 101)\n",
    " ]\n",
    "\n",
    "sample_file_path = Path.cwd().parent / 'data' / 'base_passages' / 'sample_passages_100.json'\n",
    "sample_file_path.parent.mkdir(exist_ok=True)\n",
    "\n",
    "with open(sample_file_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(sample_base_passages, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f'📝 샘플 기본 지문 생성 완료: {len(sample_base_passages)}개')\n",
    "print(f'💾 저장 위치: {sample_file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351b4ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('🚀 SPF 데이터셋 생성 시작...')\n",
    "\n",
    "spf_dataset, spf_files = create_spf_dataset(\n",
    "    passages_file='sample_passages_100.json',\n",
    "    target_pairs_per_rubric=TARGET_PAIRS_PER_RUBRIC,\n",
    "    openai_model=OPENAI_MODEL\n",
    ")\n",
    "\n",
    "print('\\n✅ SPF 데이터셋 생성 완료!')\n",
    "print('📁 저장된 파일들:')\n",
    "for rubric, file_path in spf_files.items():\n",
    "    print(f'   {rubric}: {Path(file_path).name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd5bbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_perf_passages = [\n",
    "    {\n",
    "        'id': f'high_perf_{i:03d}',\n",
    "        'text': f'고성능 모델이 생성한 우수한 품질의 지문 {i}입니다. 문법적으로 정확하고, 주제에 충실하며, 논리적으로 잘 구성되어 있습니다. 표현이 자연스럽고 완전한 정보를 제공합니다.',\n",
    "        'model': 'high_performance_7B',\n",
    "        'rubric_achievement_rate': 0.98,\n",
    "        'created_at': datetime.now().isoformat()\n",
    "    }\n",
    "    for i in range(1, 51)\n",
    " ]\n",
    "\n",
    "low_perf_passages = [\n",
    "    {\n",
    "        'id': f'low_perf_{i:03d}',\n",
    "        'text': f'저성능 모델이 생성한 지문 {i}입니다. 문법에 일부 오류가 있고, 주제에서 벗어나는 경우가 있으며, 논리적 구성이 부족할 수 있습니다.',\n",
    "        'model': 'low_performance_3B',\n",
    "        'rubric_achievement_rate': 0.40,\n",
    "        'created_at': datetime.now().isoformat()\n",
    "    }\n",
    "    for i in range(1, 51)\n",
    " ]\n",
    "\n",
    "high_perf_path = Path.cwd().parent / 'data' / 'base_passages' / 'high_performance_passages.json'\n",
    "low_perf_path = Path.cwd().parent / 'data' / 'base_passages' / 'low_performance_passages.json'\n",
    "\n",
    "with open(high_perf_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(high_perf_passages, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "with open(low_perf_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(low_perf_passages, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f'📝 고성능 모델 지문: {len(high_perf_passages)}개')\n",
    "print(f'📝 저성능 모델 지문: {len(low_perf_passages)}개')\n",
    "print(f'💾 저장 완료')\n",
    "\n",
    "print('🚀 IMP 데이터셋 생성 시작...')\n",
    "\n",
    "imp_dataset, imp_files = create_imp_dataset(\n",
    "    high_perf_file='high_performance_passages.json',\n",
    "    low_perf_file='low_performance_passages.json',\n",
    "    target_pairs_per_rubric=TARGET_PAIRS_PER_RUBRIC,\n",
    "    openai_model=OPENAI_MODEL\n",
    ")\n",
    "\n",
    "print('\\n✅ IMP 데이터셋 생성 완료!')\n",
    "print('📁 저장된 파일들:')\n",
    "for rubric, file_path in imp_files.items():\n",
    "    print(f'   {rubric}: {Path(file_path).name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ffeca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('🚀 ICP 데이터셋 생성 시작...')\n",
    "\n",
    "icp_dataset, icp_files = create_icp_dataset(\n",
    "    base_passages_file='sample_passages_100.json',\n",
    "    target_pairs_per_rubric=TARGET_PAIRS_PER_RUBRIC,\n",
    "    openai_model=OPENAI_MODEL\n",
    ")\n",
    "\n",
    "print('\\n✅ ICP 데이터셋 생성 완료!')\n",
    "print('📁 저장된 파일들:')\n",
    "for rubric, file_path in icp_files.items():\n",
    "    print(f'   {rubric}: {Path(file_path).name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a10948",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d69889",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5905399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d2940",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fd9aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (iSKA_Gen)",
   "language": "python",
   "name": "iska_gen"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
