import os
import sys
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
import uuid
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(str(Path(__file__).resolve().parents[2] / "src"))

from utils.output_loader import load_passages
from utils.benchmark_loader import load_benchmarks, get_benchmark_by_id
from utils.output_saver import save_model_output, DEFAULT_PAIRWISE_DATA_DIR


def create_passage_pairs(
    model_name: str,
    benchmark_file: str,
    benchmark_version: str = "v1.0.0",
    BENCH_ID_LIST: List[int] = [1, 2, 3, 4, 5]
) -> List[Dict[str, Any]]:
    """
    íŠ¹ì • ëª¨ë¸ì˜ ë‘ ê°€ì§€ í…œí”Œë¦¿ìœ¼ë¡œ ìƒì„±ëœ passageë“¤ì„ ë¹„êµìš© pair ë°ì´í„°ë¡œ ë§Œë“­ë‹ˆë‹¤.
    
    Args:
        model_name (str): ëª¨ë¸ ì´ë¦„
        benchmark_file (str): ë²¤ì¹˜ë§ˆí¬ íŒŒì¼ ì´ë¦„
        benchmark_version (str): ë²¤ì¹˜ë§ˆí¬ ë²„ì „
        BENCH_ID_LIST (List[int]): ì²˜ë¦¬í•  ë²¤ì¹˜ë§ˆí¬ ID ë¦¬ìŠ¤íŠ¸
        
    Returns:
        List[Dict[str, Any]]: Reward Model í•™ìŠµìš© pair ë°ì´í„°
    """
    
    pair_data = []
    
    for benchmark_id in BENCH_ID_LIST:
        print(f"\nğŸ“ ë²¤ì¹˜ë§ˆí¬ ID {benchmark_id}ì— ëŒ€í•œ passage pair ìƒì„± ì¤‘...")
        
        # 1. ë²¤ì¹˜ë§ˆí¬ ì •ë³´ ë¡œë“œ
        benchmark = get_benchmark_by_id(benchmark_file, benchmark_id)
        if not benchmark:
            print(f"âŒ ë²¤ì¹˜ë§ˆí¬ ID {benchmark_id}ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue
            
        # 2. ë‘ ê°€ì§€ í…œí”Œë¦¿ìœ¼ë¡œ ìƒì„±ëœ passage ë¡œë“œ
        chosen_passages = load_passages(
            model_name=model_name,
            benchmark_id=benchmark_id,
            benchmark_version=benchmark_version,
            template_key="passage_agent.create_passage"
        )
        
        rejected_passages = load_passages(
            model_name=model_name,
            benchmark_id=benchmark_id,
            benchmark_version=benchmark_version,
            template_key="passage_agent.create_passage_with_korean_errors"
        )
        
        if not chosen_passages:
            print(f"âŒ 'passage_agent.create_passage' í…œí”Œë¦¿ì˜ passageë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue
            
        if not rejected_passages:
            print(f"âŒ 'passage_agent.create_passage_with_korean_errors' í…œí”Œë¦¿ì˜ passageë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue
            
        print(f"âœ… Chosen passages: {len(chosen_passages)}ê°œ")
        print(f"âœ… Rejected passages: {len(rejected_passages)}ê°œ")
        
        # 3. ë²¤ì¹˜ë§ˆí¬ ì •ë³´ì—ì„œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± ìš”ì†Œ ì¶”ì¶œ
        problem_types = benchmark.get("problem_types", [])
        eval_goals = benchmark.get("eval_goals", [])
        
        # 4. Pair ë°ì´í„° ìƒì„±
        min_length = min(len(chosen_passages), len(rejected_passages))
        
        for i in range(min_length):
            chosen_passage_data = chosen_passages[i]
            rejected_passage_data = rejected_passages[i]
            
            # source_itemì´ ë™ì¼í•œì§€ í™•ì¸
            chosen_source = chosen_passage_data.get("source_item", {})
            rejected_source = rejected_passage_data.get("source_item", {})
            
            # ë™ì¼í•œ source_itemì¸ ê²½ìš°ì—ë§Œ pair ìƒì„±
            if chosen_source == rejected_source:
                # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                prompt = create_prompt_from_source(chosen_source, problem_types, eval_goals)
                
                pair_item = {
                    "data_id": f"benchmark_{benchmark_id}.item_{i}",
                    "reply_id": len(pair_data) + 1,
                    "reply_type": ["chosen", "rejected"],
                    "model_name": model_name,
                    "prompt": prompt,
                    "chosen": chosen_passage_data["generated_passage"],
                    "rejected": rejected_passage_data["generated_passage"],
                    "metadata": {
                        "benchmark_id": benchmark_id,
                        "benchmark_version": benchmark_version,
                        "source_item": chosen_source,
                        "problem_types": problem_types,
                        "eval_goals": eval_goals,
                        "chosen_template": "passage_agent.create_passage",
                        "rejected_template": "passage_agent.create_passage_with_korean_errors",
                        "created_at": datetime.now().isoformat()
                    }
                }
                
                pair_data.append(pair_item)
                
            else:
                print(f"âš ï¸ source_itemì´ ë‹¤ë¦…ë‹ˆë‹¤. item {i} ê±´ë„ˆëœ€")
                
        print(f"âœ… ë²¤ì¹˜ë§ˆí¬ ID {benchmark_id}: {min_length}ê°œ pair ìƒì„± ì™„ë£Œ")
    
    return pair_data


def create_prompt_from_source(
    source_item: Dict[str, Any],
    problem_types: List[str],
    eval_goals: List[str]
) -> str:
    """
    source_itemê³¼ ë²¤ì¹˜ë§ˆí¬ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ êµ¬ì„±í•©ë‹ˆë‹¤.
    
    Args:
        source_item (Dict[str, Any]): ì›ë³¸ ì•„ì´í…œ ì •ë³´
        problem_types (List[str]): ë¬¸ì œ ìœ í˜• ë¦¬ìŠ¤íŠ¸
        eval_goals (List[str]): í‰ê°€ ëª©í‘œ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        str: êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸
    """
    korean_topic = source_item.get("korean_topic", "")
    korean_context = source_item.get("korean_context", "")
    foreign_topic = source_item.get("foreign_topic", "")
    foreign_context = source_item.get("foreign_context", "")
    
    prompt = f"""ë‹¤ìŒ ì¡°ê±´ì— ë§ëŠ” í•œêµ­ì–´ ë…í•´ ì§€ë¬¸ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

**ì£¼ì œ ì •ë³´:**
- í•œêµ­ì–´ ì£¼ì œ: {korean_topic}
- ì™¸êµ­ì–´ ì£¼ì œ: {foreign_topic}

**ë°°ê²½ ë§¥ë½:**
- í•œêµ­ì–´ ë§¥ë½: {korean_context}
- ì™¸êµ­ì–´ ë§¥ë½: {foreign_context}

**ë¬¸ì œ ìœ í˜•:** {', '.join(problem_types)}

**í‰ê°€ ëª©í‘œ:** {', '.join(eval_goals)}

ìœ„ ì¡°ê±´ë“¤ì„ ëª¨ë‘ ë°˜ì˜í•˜ì—¬ ì ì ˆí•œ í•œêµ­ì–´ ë…í•´ ì§€ë¬¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”. ì§€ë¬¸ì€ ì£¼ì–´ì§„ ì£¼ì œì™€ ë§¥ë½ì„ í¬í•¨í•˜ê³ , ì§€ì •ëœ ë¬¸ì œ ìœ í˜•ê³¼ í‰ê°€ ëª©í‘œì— ì í•©í•´ì•¼ í•©ë‹ˆë‹¤."""

    return prompt


def save_passage_pairs(
    model_name: str,
    benchmark_file: str,
    benchmark_version: str = "v1.0.0",
    BENCH_ID_LIST: List[int] = [1, 2, 3, 4, 5]
) -> Path:
    """
    passage pair ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        model_name (str): ëª¨ë¸ ì´ë¦„
        benchmark_file (str): ë²¤ì¹˜ë§ˆí¬ íŒŒì¼ ì´ë¦„
        benchmark_version (str): ë²¤ì¹˜ë§ˆí¬ ë²„ì „
        BENCH_ID_LIST (List[int]): ì²˜ë¦¬í•  ë²¤ì¹˜ë§ˆí¬ ID ë¦¬ìŠ¤íŠ¸
        
    Returns:
        Path: ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
    """
    print(f"ğŸ”„ ëª¨ë¸ '{model_name}'ì˜ passage pair ë°ì´í„° ìƒì„± ì‹œì‘...")
    
    # pair ë°ì´í„° ìƒì„±
    pair_data = create_passage_pairs(
        model_name=model_name,
        benchmark_file=benchmark_file,
        benchmark_version=benchmark_version,
        BENCH_ID_LIST=BENCH_ID_LIST
    )
    
    if not pair_data:
        print("âŒ ìƒì„±ëœ pair ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ IDë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ì— ì €ì¥
    saved_file = save_model_output(
        model_name=f"{model_name}_reward_pairs",
        benchmark_id=0,  # ì—¬ëŸ¬ ë²¤ì¹˜ë§ˆí¬ë¥¼ í¬í•¨í•˜ë¯€ë¡œ 0ìœ¼ë¡œ ì„¤ì •
        benchmark_version=benchmark_version,
        template_key="passage_reward_pairs",
        data=pair_data,
        base_dir=DEFAULT_PAIRWISE_DATA_DIR
    )
    
    print(f"âœ… ì´ {len(pair_data)}ê°œì˜ passage pair ìƒì„± ì™„ë£Œ")
    print(f"ğŸ’¾ ì €ì¥ ìœ„ì¹˜: {saved_file}")
    
    return saved_file


def validate_pair_data(pair_data: List[Dict[str, Any]]) -> None:
    """
    ìƒì„±ëœ pair ë°ì´í„°ì˜ ìœ íš¨ì„±ì„ ê²€ì¦í•©ë‹ˆë‹¤.
    
    Args:
        pair_data (List[Dict[str, Any]]): ê²€ì¦í•  pair ë°ì´í„°
    """
    print(f"\nğŸ” Pair ë°ì´í„° ê²€ì¦ ì¤‘...")
    
    if not pair_data:
        print("âŒ ê²€ì¦í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    required_fields = ["data_id", "reply_id", "reply_type", "model_name", "prompt", "chosen", "rejected"]
    
    for i, item in enumerate(pair_data):
        # í•„ìˆ˜ í•„ë“œ í™•ì¸
        missing_fields = [field for field in required_fields if field not in item]
        if missing_fields:
            print(f"âŒ Item {i}: ëˆ„ë½ëœ í•„ë“œ {missing_fields}")
            continue
            
        # ë°ì´í„° íƒ€ì… í™•ì¸
        if not isinstance(item["prompt"], str) or not item["prompt"].strip():
            print(f"âŒ Item {i}: promptê°€ ë¹„ì–´ìˆê±°ë‚˜ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
        if not isinstance(item["chosen"], str) or not item["chosen"].strip():
            print(f"âŒ Item {i}: chosen passageê°€ ë¹„ì–´ìˆê±°ë‚˜ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            
        if not isinstance(item["rejected"], str) or not item["rejected"].strip():
            print(f"âŒ Item {i}: rejected passageê°€ ë¹„ì–´ìˆê±°ë‚˜ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    print(f"âœ… {len(pair_data)}ê°œ í•­ëª© ê²€ì¦ ì™„ë£Œ")


# --- ì‹¤í–‰ ì˜ˆì‹œ ---
if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì‹œ
    MODEL_NAME = "A.X-4.0-Light"  # ì‹¤ì œ ëª¨ë¸ëª…ìœ¼ë¡œ ë³€ê²½
    BENCHMARK_FILE = "v1/iSKA-Gen_Benchmark_v1.0.0_20250725_Initial.json"
    BENCH_ID_LIST = [1, 2, 3, 4, 5]
    
    print("ğŸš€ Passage Pair ë°ì´í„° ìƒì„± ì‹œì‘...")
    
    try:
        # Pair ë°ì´í„° ìƒì„± ë° ì €ì¥
        saved_file = save_passage_pairs(
            model_name=MODEL_NAME,
            benchmark_file=BENCHMARK_FILE,
            benchmark_version="v1.0.0",
            BENCH_ID_LIST=BENCH_ID_LIST
        )
        
        if saved_file:
            print(f"\nğŸ‰ Passage pair ë°ì´í„° ìƒì„± ì™„ë£Œ!")
            print(f"ğŸ“ íŒŒì¼ ìœ„ì¹˜: {saved_file}")
            
            # ìƒì„±ëœ ë°ì´í„° ê²€ì¦
            with open(saved_file, 'r', encoding='utf-8') as f:
                saved_data = json.load(f)
            validate_pair_data(saved_data)
            
            # ì²« ë²ˆì§¸ ì˜ˆì‹œ ì¶œë ¥
            if saved_data:
                print(f"\nğŸ“‹ ì²« ë²ˆì§¸ pair ì˜ˆì‹œ:")
                print(json.dumps(saved_data[0], ensure_ascii=False, indent=2)[:500] + "...")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
